{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns \n",
    "from scipy import stats \n",
    "import scipy \n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from the /input folder\n",
    "soccer_data = \"../input/EPL_Soccer_MLR_LR.csv\"\n",
    "df = pd.read_csv(soccer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayerName</th>\n",
       "      <th>Club</th>\n",
       "      <th>DistanceCovered(InKms)</th>\n",
       "      <th>Goals</th>\n",
       "      <th>MinutestoGoalRatio</th>\n",
       "      <th>ShotsPerGame</th>\n",
       "      <th>AgentCharges</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Cost</th>\n",
       "      <th>PreviousClubCost</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>MUN</td>\n",
       "      <td>3.96</td>\n",
       "      <td>7.5</td>\n",
       "      <td>37.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>60</td>\n",
       "      <td>20.56</td>\n",
       "      <td>109.1</td>\n",
       "      <td>63.32</td>\n",
       "      <td>195.9</td>\n",
       "      <td>78.9</td>\n",
       "      <td>19.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>MUN</td>\n",
       "      <td>4.41</td>\n",
       "      <td>8.3</td>\n",
       "      <td>38.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>68</td>\n",
       "      <td>20.67</td>\n",
       "      <td>102.8</td>\n",
       "      <td>58.55</td>\n",
       "      <td>189.7</td>\n",
       "      <td>74.4</td>\n",
       "      <td>21.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>MUN</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>11.6</td>\n",
       "      <td>21</td>\n",
       "      <td>21.86</td>\n",
       "      <td>104.6</td>\n",
       "      <td>55.36</td>\n",
       "      <td>177.8</td>\n",
       "      <td>69.1</td>\n",
       "      <td>19.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PlayerName Club  DistanceCovered(InKms)  Goals   \n",
       "0   Braund, Mr. Owen Harris  MUN                    3.96    7.5  \\\n",
       "1  Allen, Mr. William Henry  MUN                    4.41    8.3   \n",
       "2          Moran, Mr. James  MUN                    4.14    5.0   \n",
       "\n",
       "   MinutestoGoalRatio  ShotsPerGame  AgentCharges    BMI   Cost   \n",
       "0                37.5          12.3            60  20.56  109.1  \\\n",
       "1                38.2          12.7            68  20.67  102.8   \n",
       "2                36.4          11.6            21  21.86  104.6   \n",
       "\n",
       "   PreviousClubCost  Height  Weight  Score  \n",
       "0             63.32   195.9    78.9  19.75  \n",
       "1             58.55   189.7    74.4  21.30  \n",
       "2             55.36   177.8    69.1  19.88  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view top 3 observations from the soccer data\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PlayerName', 'Club', 'DistanceCovered(InKms)', 'Goals',\n",
       "       'MinutestoGoalRatio', 'ShotsPerGame', 'AgentCharges', 'BMI', 'Cost',\n",
       "       'PreviousClubCost', 'Height', 'Weight', 'Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list out the columns\n",
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 202 entries, 0 to 201\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   PlayerName              202 non-null    object \n",
      " 1   Club                    202 non-null    object \n",
      " 2   DistanceCovered(InKms)  202 non-null    float64\n",
      " 3   Goals                   202 non-null    float64\n",
      " 4   MinutestoGoalRatio      202 non-null    float64\n",
      " 5   ShotsPerGame            202 non-null    float64\n",
      " 6   AgentCharges            202 non-null    int64  \n",
      " 7   BMI                     202 non-null    float64\n",
      " 8   Cost                    202 non-null    float64\n",
      " 9   PreviousClubCost        202 non-null    float64\n",
      " 10  Height                  202 non-null    float64\n",
      " 11  Weight                  202 non-null    float64\n",
      " 12  Score                   202 non-null    float64\n",
      "dtypes: float64(10), int64(1), object(2)\n",
      "memory usage: 20.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# dataframe information - prints information about the dataframe including index, dtype and columns, non-null values, and memory usage.\n",
    "# It can be used to get basic info, look for missing values, and get a sense of each variable's format.\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 202 rows, 13 columns in the dataset. Observe that there are no null values. Out of 13 columns, 10 are float type and 1 is integer type. The remaining 2 have object dtype."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descriptive statistics**    \n",
    "To generate descriptive statistics pandas.dataframe.describe() funtion is used.    \n",
    "*Descriptive statistics* include those that summarize the central tendency, dispersion, and shape of a dataset's distribution, excluding NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DistanceCovered(InKms)</th>\n",
       "      <th>Goals</th>\n",
       "      <th>MinutestoGoalRatio</th>\n",
       "      <th>ShotsPerGame</th>\n",
       "      <th>AgentCharges</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Cost</th>\n",
       "      <th>PreviousClubCost</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.718614</td>\n",
       "      <td>7.108663</td>\n",
       "      <td>43.091584</td>\n",
       "      <td>14.566337</td>\n",
       "      <td>76.876238</td>\n",
       "      <td>22.955891</td>\n",
       "      <td>69.021782</td>\n",
       "      <td>64.873713</td>\n",
       "      <td>180.103960</td>\n",
       "      <td>75.008168</td>\n",
       "      <td>13.507426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.457976</td>\n",
       "      <td>1.800549</td>\n",
       "      <td>3.662989</td>\n",
       "      <td>1.362451</td>\n",
       "      <td>47.501239</td>\n",
       "      <td>2.863933</td>\n",
       "      <td>32.565333</td>\n",
       "      <td>13.070197</td>\n",
       "      <td>9.734494</td>\n",
       "      <td>13.925574</td>\n",
       "      <td>6.189826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>35.900000</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.360000</td>\n",
       "      <td>148.900000</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>5.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.372500</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>40.600000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>21.082500</td>\n",
       "      <td>43.850000</td>\n",
       "      <td>54.667500</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>66.525000</td>\n",
       "      <td>8.545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.755000</td>\n",
       "      <td>6.850000</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>22.720000</td>\n",
       "      <td>58.600000</td>\n",
       "      <td>63.035000</td>\n",
       "      <td>179.700000</td>\n",
       "      <td>74.400000</td>\n",
       "      <td>11.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.030000</td>\n",
       "      <td>8.275000</td>\n",
       "      <td>45.575000</td>\n",
       "      <td>15.575000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>24.465000</td>\n",
       "      <td>90.350000</td>\n",
       "      <td>74.750000</td>\n",
       "      <td>186.175000</td>\n",
       "      <td>84.125000</td>\n",
       "      <td>18.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.720000</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>59.700000</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>34.420000</td>\n",
       "      <td>200.800000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>209.400000</td>\n",
       "      <td>123.200000</td>\n",
       "      <td>35.520000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DistanceCovered(InKms)       Goals  MinutestoGoalRatio  ShotsPerGame   \n",
       "count              202.000000  202.000000          202.000000    202.000000  \\\n",
       "mean                 4.718614    7.108663           43.091584     14.566337   \n",
       "std                  0.457976    1.800549            3.662989      1.362451   \n",
       "min                  3.800000    3.300000           35.900000     11.600000   \n",
       "25%                  4.372500    5.900000           40.600000     13.500000   \n",
       "50%                  4.755000    6.850000           43.500000     14.700000   \n",
       "75%                  5.030000    8.275000           45.575000     15.575000   \n",
       "max                  6.720000   14.300000           59.700000     19.200000   \n",
       "\n",
       "       AgentCharges         BMI        Cost  PreviousClubCost      Height   \n",
       "count    202.000000  202.000000  202.000000        202.000000  202.000000  \\\n",
       "mean      76.876238   22.955891   69.021782         64.873713  180.103960   \n",
       "std       47.501239    2.863933   32.565333         13.070197    9.734494   \n",
       "min        8.000000   16.750000   28.000000         34.360000  148.900000   \n",
       "25%       41.250000   21.082500   43.850000         54.667500  174.000000   \n",
       "50%       65.500000   22.720000   58.600000         63.035000  179.700000   \n",
       "75%       97.000000   24.465000   90.350000         74.750000  186.175000   \n",
       "max      234.000000   34.420000  200.800000        106.000000  209.400000   \n",
       "\n",
       "           Weight       Score  \n",
       "count  202.000000  202.000000  \n",
       "mean    75.008168   13.507426  \n",
       "std     13.925574    6.189826  \n",
       "min     37.800000    5.630000  \n",
       "25%     66.525000    8.545000  \n",
       "50%     74.400000   11.650000  \n",
       "75%     84.125000   18.080000  \n",
       "max    123.200000   35.520000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation**    \n",
    "Correlation coefficient is used to measure the strength of relationship between two variables. It indicates that as the value of one variable changes the other variable changes in a specific direction with some magnitude. There are various ways to find correlation between two variables, one of which is Pearson correlation coefficient.\n",
    "It measures the linear relationship between two continuous variables.     \n",
    "Let's say $x$ and $y$ are two continuous variables, the Pearson correlation coefficient between them can be found by the following formula.\n",
    " \n",
    " \n",
    "$$r = \\frac{ \\sum_{i=1}^{n}(x_i-\\bar{x})(y_i-\\bar{y}) }{%\n",
    "        \\sqrt{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^{n}(y_i-\\bar{y})^2}}$$\n",
    " \n",
    "where $x_i$ and $y_i$ represents the $i^{th}$ value of the variables.\n",
    "The value of $r$ ranges between $-1$ and $+1$.\n",
    " \n",
    "Their strength of relationship is measured by the absolute value of coefficient, whereas the sign of the coefficient indicates the direction of the relationship."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find correlation between variables from the soccer data we will use pandas.dataframe.corr() method.\n",
    "\n",
    "It computes pairwise correlation between two columns by excluding NA or NaN values if any. The default method used to calculate correlation coefficient is pearson correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DistanceCovered(InKms)</th>\n",
       "      <th>Goals</th>\n",
       "      <th>MinutestoGoalRatio</th>\n",
       "      <th>ShotsPerGame</th>\n",
       "      <th>AgentCharges</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Cost</th>\n",
       "      <th>PreviousClubCost</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DistanceCovered(InKms)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.147098</td>\n",
       "      <td>0.924964</td>\n",
       "      <td>0.888800</td>\n",
       "      <td>0.250865</td>\n",
       "      <td>0.299471</td>\n",
       "      <td>-0.403004</td>\n",
       "      <td>0.550975</td>\n",
       "      <td>0.358854</td>\n",
       "      <td>0.403743</td>\n",
       "      <td>-0.493512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goals</th>\n",
       "      <td>0.147098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.153333</td>\n",
       "      <td>0.134721</td>\n",
       "      <td>0.131973</td>\n",
       "      <td>0.177032</td>\n",
       "      <td>0.137131</td>\n",
       "      <td>0.102734</td>\n",
       "      <td>0.076958</td>\n",
       "      <td>0.155844</td>\n",
       "      <td>0.108114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinutestoGoalRatio</th>\n",
       "      <td>0.924964</td>\n",
       "      <td>0.153333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950757</td>\n",
       "      <td>0.258240</td>\n",
       "      <td>0.320527</td>\n",
       "      <td>-0.449135</td>\n",
       "      <td>0.583375</td>\n",
       "      <td>0.371192</td>\n",
       "      <td>0.423699</td>\n",
       "      <td>-0.532449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShotsPerGame</th>\n",
       "      <td>0.888800</td>\n",
       "      <td>0.134721</td>\n",
       "      <td>0.950757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.308391</td>\n",
       "      <td>0.382524</td>\n",
       "      <td>-0.435429</td>\n",
       "      <td>0.610986</td>\n",
       "      <td>0.352322</td>\n",
       "      <td>0.455255</td>\n",
       "      <td>-0.531522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgentCharges</th>\n",
       "      <td>0.250865</td>\n",
       "      <td>0.131973</td>\n",
       "      <td>0.258240</td>\n",
       "      <td>0.308391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.302556</td>\n",
       "      <td>-0.108243</td>\n",
       "      <td>0.317581</td>\n",
       "      <td>0.123255</td>\n",
       "      <td>0.273686</td>\n",
       "      <td>-0.183386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.299471</td>\n",
       "      <td>0.177032</td>\n",
       "      <td>0.320527</td>\n",
       "      <td>0.382524</td>\n",
       "      <td>0.302556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.321116</td>\n",
       "      <td>0.713858</td>\n",
       "      <td>0.337097</td>\n",
       "      <td>0.845955</td>\n",
       "      <td>0.187558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cost</th>\n",
       "      <td>-0.403004</td>\n",
       "      <td>0.137131</td>\n",
       "      <td>-0.449135</td>\n",
       "      <td>-0.435429</td>\n",
       "      <td>-0.108243</td>\n",
       "      <td>0.321116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.207749</td>\n",
       "      <td>-0.071253</td>\n",
       "      <td>0.154227</td>\n",
       "      <td>0.963017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PreviousClubCost</th>\n",
       "      <td>0.550975</td>\n",
       "      <td>0.102734</td>\n",
       "      <td>0.583375</td>\n",
       "      <td>0.610986</td>\n",
       "      <td>0.317581</td>\n",
       "      <td>0.713858</td>\n",
       "      <td>-0.207749</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802119</td>\n",
       "      <td>0.930904</td>\n",
       "      <td>-0.361850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>0.358854</td>\n",
       "      <td>0.076958</td>\n",
       "      <td>0.371192</td>\n",
       "      <td>0.352322</td>\n",
       "      <td>0.123255</td>\n",
       "      <td>0.337097</td>\n",
       "      <td>-0.071253</td>\n",
       "      <td>0.802119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780906</td>\n",
       "      <td>-0.188022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>0.403743</td>\n",
       "      <td>0.155844</td>\n",
       "      <td>0.423699</td>\n",
       "      <td>0.455255</td>\n",
       "      <td>0.273686</td>\n",
       "      <td>0.845955</td>\n",
       "      <td>0.154227</td>\n",
       "      <td>0.930904</td>\n",
       "      <td>0.780906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <td>-0.493512</td>\n",
       "      <td>0.108114</td>\n",
       "      <td>-0.532449</td>\n",
       "      <td>-0.531522</td>\n",
       "      <td>-0.183386</td>\n",
       "      <td>0.187558</td>\n",
       "      <td>0.963017</td>\n",
       "      <td>-0.361850</td>\n",
       "      <td>-0.188022</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        DistanceCovered(InKms)     Goals  MinutestoGoalRatio   \n",
       "DistanceCovered(InKms)                1.000000  0.147098            0.924964  \\\n",
       "Goals                                 0.147098  1.000000            0.153333   \n",
       "MinutestoGoalRatio                    0.924964  0.153333            1.000000   \n",
       "ShotsPerGame                          0.888800  0.134721            0.950757   \n",
       "AgentCharges                          0.250865  0.131973            0.258240   \n",
       "BMI                                   0.299471  0.177032            0.320527   \n",
       "Cost                                 -0.403004  0.137131           -0.449135   \n",
       "PreviousClubCost                      0.550975  0.102734            0.583375   \n",
       "Height                                0.358854  0.076958            0.371192   \n",
       "Weight                                0.403743  0.155844            0.423699   \n",
       "Score                                -0.493512  0.108114           -0.532449   \n",
       "\n",
       "                        ShotsPerGame  AgentCharges       BMI      Cost   \n",
       "DistanceCovered(InKms)      0.888800      0.250865  0.299471 -0.403004  \\\n",
       "Goals                       0.134721      0.131973  0.177032  0.137131   \n",
       "MinutestoGoalRatio          0.950757      0.258240  0.320527 -0.449135   \n",
       "ShotsPerGame                1.000000      0.308391  0.382524 -0.435429   \n",
       "AgentCharges                0.308391      1.000000  0.302556 -0.108243   \n",
       "BMI                         0.382524      0.302556  1.000000  0.321116   \n",
       "Cost                       -0.435429     -0.108243  0.321116  1.000000   \n",
       "PreviousClubCost            0.610986      0.317581  0.713858 -0.207749   \n",
       "Height                      0.352322      0.123255  0.337097 -0.071253   \n",
       "Weight                      0.455255      0.273686  0.845955  0.154227   \n",
       "Score                      -0.531522     -0.183386  0.187558  0.963017   \n",
       "\n",
       "                        PreviousClubCost    Height    Weight     Score  \n",
       "DistanceCovered(InKms)          0.550975  0.358854  0.403743 -0.493512  \n",
       "Goals                           0.102734  0.076958  0.155844  0.108114  \n",
       "MinutestoGoalRatio              0.583375  0.371192  0.423699 -0.532449  \n",
       "ShotsPerGame                    0.610986  0.352322  0.455255 -0.531522  \n",
       "AgentCharges                    0.317581  0.123255  0.273686 -0.183386  \n",
       "BMI                             0.713858  0.337097  0.845955  0.187558  \n",
       "Cost                           -0.207749 -0.071253  0.154227  0.963017  \n",
       "PreviousClubCost                1.000000  0.802119  0.930904 -0.361850  \n",
       "Height                          0.802119  1.000000  0.780906 -0.188022  \n",
       "Weight                          0.930904  0.780906  1.000000 -0.000162  \n",
       "Score                          -0.361850 -0.188022 -0.000162  1.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, 2:].corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between DistanceCovered(InKms) and the target variable score $-0.49$ indicates negative correlation.\n",
    "The variable cost is related to the target variable with correlation coefficient $0.96$ which indicates strong positive relationship. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson correlation coefficient can only measure linear relationship between data.\n",
    "The following data shows non linear relationship which can not be found by using pearson correlation coefficient. In such cases Spearman's correlation coefficient is used. It can be used to find nonlinear, monotonic relationships and for ordinal data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation does not imply Causation!!**\n",
    " \n",
    "Some studies show that people in the UK spend more money on shopping when it's cold which shows correlation between two variables. Does this imply cold weather causes people to spend more money? The answer is NO. One of the possible explanations is that cold weather coincides with Christmas and new year sales, hence people shop more.\n",
    " \n",
    "Correlation between two variables indicates association between two variables but it does not mean change in one variable is caused by another."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relationship between Cost and Score**\n",
    "\n",
    "Score and Cost have a 96% correlation, making it a significant variable. Cost can be selected as the predictor variable for simple linear regression since the scatter plot between them will demonstrate a linear relationship.\n",
    "\n",
    "\n",
    "To see this relationship visually, let's plot the scatter plot for Cost and Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Scatter plot between Cost and Score')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(figsize=(8, 6), dpi=80)\n",
    "plt.scatter(df['Cost'], df['Score'])\n",
    "\n",
    "# label\n",
    "plt.xlabel(\"Cost\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Scatter plot between Cost and Score\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between Cost and Score is easily visible here.\n",
    " \n",
    "The Pearson correlation and scatter plot demonstrate that as the cost increases, so does the score. But what can we do with this knowledge?\n",
    " \n",
    "How can we know how much money should be spent to achieve a specific score?\n",
    "This is where Linear Regression comes in. It assists us in modeling the linear relationship between two or more variables so that we may foresee the results using the model.\n",
    " \n",
    "Let's figure out how."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train - Test Split**     \n",
    "The data points are divided into two datasets, train and test, in a train test split method. The train data is used to train the model, and the model is then used to predict on the test data to see how the model performs on unseen data and whether it is overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X, y predictor and response variables\n",
    "X = df['Cost']\n",
    "y = df['Score']\n",
    "\n",
    "# Splitting with 75% training and 25% testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=0.25, random_state=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Underfitting and Overfitting**\n",
    " \n",
    "* **Underfitting**: Underfitting occurs when a statistical model or machine learning algorithm fails to capture the underlying trend of the data, i.e., it performs well on training data but poorly on testing data. Its occurrence merely indicates that our model or method does not adequately suit the data. It frequently occurs when we select a simpler model yet the data contains complicated non-linear patterns or when there is insufficient data to develop a linear model. The obvious approach is to build a complex model or increase the number of linear features in the data.\n",
    " \n",
    "* **Overfitting**: When a statistical model fails to produce correct predictions on testing data, it is said to be overfitted. When a model is trained with a large amount of data, it begins to learn from the noise and incorrect data entries in our data set. It usually occurs when we build a complex model on a simpler dataset.\n",
    "An overfitted model performs well on training data because it has memorized the patterns in the data, but it performs poorly on testing data. An under-fitted model, on the other hand, will perform worse on both datasets because it is unable to capture the trends and patterns underlying the dataset when training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression**     \n",
    "Linear Regression is a statistical approach to modeling the linear relationship between predictor variables and the target variable. These variables are known as the independent and dependent variables, respectively.    \n",
    "\n",
    "When there is one independent variable, it is known as **Simple Linear Regression**. When there are more independent variables, it is called **Multiple Linear Regression**.    \n",
    "\n",
    "Mathematics behind the linear regression:    \n",
    "\n",
    "**Simple Linear Regression**:   $\\hat y = \\beta_0+\\beta_1x+\\epsilon$\n",
    "\n",
    "**Multiple Linear Regression**: $\\hat y = \\beta_0+\\beta_1x_1+\\dots \\beta_px_p+\\epsilon$ where $p$ is... number of features in the model.    \n",
    "\n",
    "Linear regression serves two primary functions: understanding variable relationships and forecasting:    \n",
    "- The coefficients represents the estimated magnitude and direction (positive/negative) of each independent variable's relationship with the dependent variable.    \n",
    "- A linear regression equation predicts the mean value of the dependent variable given the values of the independent variables. So, it enables us to forecast."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Errors in Regression**     \n",
    "The regression line regress towards the Mean to create the best fit which essentially means that the errors are at the lowest. The regression line is not able to exactly predict the true values, there is always going to be some errors.    \n",
    "\n",
    "Various Errors in Regression:    \n",
    "- The mean absolute error (MAE) is the most basic regression error statistic. We'll compute the residuals of each data point individually, using only absolute value of each so that negative and positive residuals don't cancel out. The average of all these residuals is then calculated. MAE essentially describes the typical magnitude of the residuals.     \n",
    "$$MAE = \\frac{1}{n}\\sum_{i=1}^{n}|y-\\hat y|$$    \n",
    "\n",
    "- The mean square error (MSE) is identical to the mean absolute error (MAE) but squares the difference before aggregating all of them. The MSE will nearly always be greater than the MAE because we are squaring the difference. Because of this, we are unable to directly compare the MAE and MSE. We are limited to comparing the error metrics of our model to those of a rival model. The presence of outliers in our data makes the square term's impact on the MSE equation very clear. In MAE, each residual adds proportionally to the overall error, whereas in MSE, the error increases quadratically. As a result, our data outliers will ultimately result in a considerably bigger total error in the MSE than they will in the MAE. Similarly to this, our model will suffer more if it predicts values that are significantly different from the matching actual value.\n",
    "This means that in MSE as opposed to MAE, substantial disparities between actual and predicted values are punished more severely. <br>If we wish to limit the importance of outliers, we should use MAE because outlier residuals do not contribute as much to overall error as MSE. Finally, the decision between MSE and MAE is application-specific and depends on how large errors need to be handled.\n",
    " \n",
    "$$MSE= \\frac{1}{n}\\sum_{i=1}^{n}(y-\\hat y)^2$$    \n",
    "\n",
    "- The root mean squared error (RMSE) is another error statistic. It is the square root of the MSE, as the name implies. Because the MSE is squared, its units differ from the original output. RMSE is frequently used to transform the error metric back into comparable units, making interpretation easier. Outliers have a comparable effect on the MSE and RMSE because they both square the residual.\n",
    " \n",
    "$$RMSE= \\sqrt(\\frac{1}{n}\\sum_{i=1}^{n}(y-\\hat y)^2)$$    \n",
    "\n",
    "- The percentage counterpart of MAE is the mean absolute percentage error (MAPE). Just as MAE is the average amount of error created by your model, MAPE is the average distance between the model's predictions and their associated outputs. MAPE, like MAE, has a clear meaning because percentages are easier for people to understand. Because of the use of absolute value, MAPE and MAE are both resistant to the effects of outliers.\n",
    " \n",
    "$$MAPE= \\frac{100\\%}{n}\\ \\sum_{i=1}^{n}\\left| \\frac{y-\\hat y}{y} \\right|$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the Best Fit Line**     \n",
    "We can proceed with the Linear Regression model after determining the correlation between the variables, independent variable, and target variable, and if the variables are linearly correlated. The objective of finding the coefficients is to minimize the difference between actual values of the target variable and the predicted values.    \n",
    "\n",
    "The Linear Regression model will determine the best fit line for the scatter of data points.\n",
    " \n",
    "The equation of the regression line is :\n",
    " \n",
    "$$y=\\beta_0+\\beta_1x$$\n",
    " \n",
    "where $\\beta_0$ and $\\beta_1$ are regression coefficients.    \n",
    "\n",
    "We can have infinite possibilities for the values of the regression coefficients. How do you find the best fit line out of the possible values?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cost Function**    \n",
    "The cost function assesses how well a machine learning model performs. The cost function calculates the difference between predicted and actual values as a single real number.    \n",
    "\n",
    "**Loss Function**    \n",
    "The loss function is the error for individual data points, while the cost function is the average error of n-samples in the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Residual Sum of Squares(RSS) or Sum of Squared Errors(SSE)**    \n",
    "Ordinary least square or Residual Sum of squares (RSS) or Sum of Squared Errors (SSE) is minimized to find the value of 0 and 1, to find the best fit of the predicted line.\n",
    " \n",
    "$$ MSE = \\frac{1}{N} RSS = \\frac{1}{N}\\sum_{i=1}^{n}(y-\\hat y)^2 $$\n",
    " \n",
    "Hence,\n",
    " \n",
    "$$SSE = \\sum_{i=1}^{n}(y-\\hat y)^2 $$\n",
    " \n",
    "There are two main methods to find the coefficients of linear regression: least squares and gradient descent.\n",
    " \n",
    "**Least Squares Estimators**     \n",
    "One of the methods to optimize the Linear Regression equation for the minimum SSE is using Least Squares Estimators. These are the following steps involved in finding out the best fit line parameters:     \n",
    "1. Differentiate the SSE with respect to $\\beta_0$ and $\\beta_1$     \n",
    "2. Setting the partial derivatives equal to zero yields **normal equations** which can then be manipulated to find $\\beta_0$ and $\\beta_1$ for the minimum SSE.\n",
    "  \n",
    "**Gradient Descent**     \n",
    "Gradient descent is an optimization algorithm that iteratively adjusts the coefficients to minimize the cost function. The cost function measures the difference between the actual and predicted values. The gradient descent algorithm updates the coefficients using the gradient of the cost function. The gradient of the cost function gives us the direction of the steepest descent, which we use to adjust the coefficients. The process is repeated until the cost function reaches a minimum."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression: Scikit-learn vs Statsmodels**    \n",
    "Scikit-learn's LinearRegression and Statsmodels' OLS (Ordinary Least Squares) are two popular libraries for linear regression in Python. While both can be used to perform linear regression, there are some differences between them:\n",
    "\n",
    "* Model Fitting: Scikit-learn provides a simple API for model fitting. The fit method of the LinearRegression class takes in the input features and target variable, and returns the fitted model. On the other hand, Statsmodels provides a more detailed and statistically rigorous approach to model fitting with its OLS class, which allows users to specify various model assumptions, summary statistics and hypothesis testing.\n",
    "\n",
    "* Model Summary: Scikit-learn provides only the coefficients and their standard errors, while Statsmodels provides a more detailed summary of the regression results, including R-squared, F-statistic, p-values, and confidence intervals for the coefficients. This can be useful for hypothesis testing and model selection.\n",
    "\n",
    "* Model Evaluation: Scikit-learn provides several evaluation metrics for regression models, such as mean squared error, mean absolute error, and R-squared. Statsmodels provides similar metrics, but also offers the ability to run hypothesis tests on the coefficients, such as t-tests and F-tests, which are useful for model selection and inference.\n",
    "\n",
    "* Speed: Scikit-learn's LinearRegression is optimized for speed, making it a good choice for large datasets. Statsmodels' OLS is less optimized for speed, and can be slower for large datasets.\n",
    "\n",
    "In conclusion, when it comes to choosing between the two, it depends on the specific requirements of the project. If a simple, fast, and flexible linear regression model is needed, scikit-learn's LinearRegression is a good choice. If a more detailed statistical analysis of the regression results is needed, with the ability to perform hypothesis tests and perform detailed evaluation, then Statsmodels' OLS may be a better choice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Point Estimator of the Mean Response**     \n",
    "Point estimators of the mean response in linear regression - refer to estimates of the expected value of the response variable for a given predictor variable. These estimates are calculated using the estimated coefficients of the regression line, which are obtained through regression analysis.\n",
    "\n",
    "In linear regression, the mean response is modeled as a linear combination of the predictor variables, where the coefficients represent the effect of each predictor on the response.      \n",
    "\n",
    "Given a set of predictor variables, the point estimator for the mean response can be calculated by plugging in the values of the predictors into the regression equation and solving for the expected value of the response.\n",
    "\n",
    "Point estimators are useful because they provide a quick and straightforward way to make predictions about the mean response for a given set of predictor values. However, it is important to keep in mind that point estimators are just estimates and are subject to sampling variability and other sources of error. Therefore, it is common to also provide confidence intervals or prediction intervals along with point estimators to account for uncertainty in the predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Point Estimator of the Variance**    \n",
    "In linear regression, the variance of the error (also called residual variance) is a measure of the spread of the residuals around the fitted line. The residuals are the differences between the observed values and the values predicted by the regression model.\n",
    "\n",
    "The point estimator of the variance of the error is the mean squared error (MSE) divided by the degrees of freedom (n-p-1), where n is the number of observations and p is the number of predictors in the model. The formula for the point estimator of the variance of the error is:\n",
    "\n",
    "$\\hat{\\sigma}^2 = \\frac{1}{n-p-1} \\sum_{i=1}^n (y_i - \\hat{y_i})^2$\n",
    "\n",
    "where $\\hat{y_i}$ is the predicted value for the i-th observation, and $y_i$ is the observed value.     \n",
    "\n",
    "The MSE is a measure of the overall fit of the regression model. The smaller the MSE, the better the fit of the model. The variance of the error provides information on the spread of the residuals, which can be used to determine the reliability of the regression model.\n",
    "\n",
    "In summary, the point estimator of the variance of the error is an important quantity in linear regression as it provides information on the spread of the residuals, which can be used to evaluate the fit of the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
